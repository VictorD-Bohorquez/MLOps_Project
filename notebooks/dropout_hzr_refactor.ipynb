{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset (filename, path = None):\n",
    "    if path is None:\n",
    "        os.chdir(r'C:\\Users\\hzapi\\OneDrive\\Documents\\Hans Files\\07_MNA\\13_TC5044_Operaciones de aprendizaje autom√°tico\\98_Git\\MLOps_Project\\data\\raw')\n",
    "        df_read = pd.read_csv(filename, sep=';')\n",
    "        print ('Read OS success')\n",
    "    else:\n",
    "        path_dir = path + '\\\\' + filename\n",
    "        df_read = pd.read_csv(filename, sep=';')\n",
    "        print ('Read path success')\n",
    "    return  df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model (name,prefix, path):\n",
    "        header = get_df_name(df_interest).lower()\n",
    "        name = 'model_demand_' + header + '_rf.pkl'\n",
    "        save_demand_models(best_model, scaler, path, name)\n",
    "        print (f'Model Saved as: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering (df_interest, target):\n",
    "    df_filter = df_interest[df_interest['Age at enrollment'] <= df_interest['Age at enrollment'].quantile(0.90)].copy()\n",
    "    df_filter[target] = df_filter[target].fillna('Unknown')\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    df_filter['encoded_target'] = label_encoder.fit_transform(df_filter[target])\n",
    "    \n",
    "    #encoder = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "    #one_hot_encoded = encoder.fit_transform(df_filter[[target[0]]])\n",
    "    #new_target = encoder.get_feature_names_out([target[0]])\n",
    "    #one_hot_df = pd.DataFrame(one_hot_encoded, columns = new_target, index = df_filter.index)\n",
    "\n",
    "    #df_encoded = pd.concat([df_filter, one_hot_df], axis = 1)\n",
    "    #df_encoded = df_encoded.drop(target, axis = 1)\n",
    "\n",
    "    #if df_encoded.isnull().sum().sum() > 0:\n",
    "    #    print(\"Warning: NaN values found after encoding.\")\n",
    "    #    print(df_encoded.isnull().sum())\n",
    "    #    return\n",
    "\n",
    "    df_filter = df_filter.drop(target, axis = 1)\n",
    "\n",
    "    return df_filter, df_filter['encoded_target'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_prep(df_interest, features, target, train_split = 0.3):\n",
    "    alt_df, new_target = feature_engineering(df_interest.copy(), target)\n",
    "\n",
    "    features_df = alt_df[features].copy()\n",
    "    target_df = alt_df[new_target].copy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size = train_split, random_state = 42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    y_val = y_val.values.ravel()\n",
    "\n",
    "    return alt_df, scaler, X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid_search(model, param_grid, X_train, X_test, y_train, y_test):\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train.ravel())\n",
    "    best_mod = grid_search.best_estimator_\n",
    "    y_pred = best_mod.predict(X_test)\n",
    "    return  best_mod, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    print(f'Dropout Model Accuracy: {accuracy}, Precision: {precision}, Recall: {recall})')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model (df_interest, model_name, model_type, features, target, param_grid, save_model = False, path = None):\n",
    "    print(f'Model Training: ', model_name)\n",
    "    alt_df, scaler, X_train, X_test, X_val, y_train, y_test, y_val = model_data_prep(df_interest, features, target)\n",
    "    best_model, y_pred = model_grid_search(model_type, param_grid, X_train, X_test, y_train, y_test)\n",
    "    performance_metrics(y_test, y_pred)\n",
    "\n",
    "    if save_model:\n",
    "        header = get_df_name(df_interest).lower()\n",
    "        name = 'model_demand_' + header + '_knn.pkl'\n",
    "        save_demand_models(best_model, scaler, path, name)\n",
    "        print (f'Model Saved as: {name}')\n",
    "\n",
    "    return best_model, X_train, scaler, alt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dropout(input_data, model_name, model_type, features, target,  param_grid, save_model = False, path = None):\n",
    "    model, X_train, scaler, features_refined = setup_model(input_data, model_name, model_type, features, target, param_grid, save_model, path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state = 42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state = 42),\n",
    "        'XGBoost': XGBClassifier(random_state = 42),\n",
    "        'Light GBM': LGBMClassifier(random_state = 42, verbosity = -1),\n",
    "        'SVC': SVC(),\n",
    "        'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "        'Random Forest': \n",
    "        {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20, 30],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        \n",
    "        'Gradient Boosting': \n",
    "        {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 4, 5] \n",
    "        },\n",
    "\n",
    "        'XGBoost': \n",
    "        {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 4, 5]\n",
    "        },\n",
    "        \n",
    "        'Light GBM': \n",
    "        {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 4, 5]\n",
    "        },\n",
    "        'SVC': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'gamma': [0.01, 0.1, 1],\n",
    "                'kernel': ['linear', 'rbf']\n",
    "        },        \n",
    "        'KNN': {\n",
    "                'n_neighbors': [3, 5, 10],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read OS success\n"
     ]
    }
   ],
   "source": [
    "df_student = load_dataset('data.csv')\n",
    "model_target = ['Target']\n",
    "model_features = df_student.copy().drop(model_target, axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training:  Random Forest\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.7575250836120402, Precision: 0.7371038672186181, Recall: 0.7575250836120402)\n",
      "Model Training:  Gradient Boosting\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.7725752508361204, Precision: 0.7578945764669582, Recall: 0.7725752508361204)\n",
      "Model Training:  XGBoost\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.7692307692307693, Precision: 0.7507798298652871, Recall: 0.7692307692307693)\n",
      "Model Training:  Light GBM\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.7692307692307693, Precision: 0.7536317274274268, Recall: 0.7692307692307693)\n",
      "Model Training:  SVC\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.774247491638796, Precision: 0.7599055274643832, Recall: 0.774247491638796)\n",
      "Model Training:  KNN\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hzapi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Model Accuracy: 0.7224080267558528, Precision: 0.7025216501553763, Recall: 0.7224080267558528)\n"
     ]
    }
   ],
   "source": [
    "for index, (model_name, model) in enumerate(models.items()):\n",
    "    model_name, model_param = list(param_grid.items()) [index]\n",
    "    predict_dropout(df_student, model_name, model, model_features, model_target, model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Light GBM\n",
      "SVC\n",
      "KNN\n"
     ]
    }
   ],
   "source": [
    "for index, (model_name, model) in enumerate(models.items()):\n",
    "    model_name, model_param = list(param_grid.items()) [index]\n",
    "    print(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
